{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "696200a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download dataset\n",
    "\n",
    "import requests\n",
    "import os\n",
    "\n",
    "if not 'shakespeare.txt' in os.listdir('./'):\n",
    "    r = requests.get('https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')\n",
    "    open('shakespeare.txt', 'wb').write(r.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6052b848",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# For every character create distinct ID and encode the text\n",
    "n_chars = 0\n",
    "\n",
    "with open('shakespeare.txt', 'r') as f:\n",
    "    char2ids = {}\n",
    "    idx2char = {}\n",
    "    encoded = []\n",
    "    for l in f.readlines():\n",
    "        for char in l:\n",
    "            n_chars += 1\n",
    "            if char not in char2ids.keys():\n",
    "                char2ids[char] = len(char2ids) + 1\n",
    "                idx2char[len(char2ids) + 1] = char\n",
    "            encoded.append(char2ids[char])    \n",
    "    encoded = np.array(encoded, dtype=np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "165a8c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class ShakespeareDataset(Dataset):\n",
    "    def __init__(self, encoded, n_unique_chars, window_size=101):\n",
    "        self.n_unique_chars = n_unique_chars\n",
    "        self.encoded = torch.tensor(encoded, dtype=torch.float)\n",
    "        self.window_size = window_size\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.encoded) - self.window_size - 1\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        window = self.encoded[idx:idx+self.window_size]\n",
    "        return window[:-1].long(), window[1:].long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d649500",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1003854\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([100])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_size = int(n_chars * 0.9) # Take 90% of text as training data\n",
    "print(train_size)\n",
    "train_dataset = ShakespeareDataset(encoded[:train_size], len(char2ids))\n",
    "train_dataset[1][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3bf9cab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f76d34d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "\n",
    "class CharRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
    "        super(CharRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.embed = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.LSTM(hidden_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, X, hidden, cell):\n",
    "        X = self.embed(X)\n",
    "        X, (hidden, cell) = self.gru(X.unsqueeze(1), (hidden, cell))\n",
    "        X = self.out(X.reshape(X.shape[0], -1))\n",
    "        return X, hidden, cell\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        hidden = torch.zeros(self.num_layers, batch_size, self.hidden_size).to(device)\n",
    "        cell = torch.zeros(self.num_layers, batch_size, self.hidden_size).to(device)\n",
    "        return hidden, cell\n",
    "    \n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
    "        super(RNN, self).__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embed = nn.Embedding(input_size, hidden_size)\n",
    "        self.lstm = nn.LSTM(hidden_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, X, hidden, cell):\n",
    "        print(X.shape)\n",
    "        out = self.embed(X)\n",
    "        print(out.shape)\n",
    "        out, (hidden, cell) = self.lstm(out.unsqueeze(1), (hidden, cell))\n",
    "        print(out.shape)\n",
    "        out = self.fc(out.reshape(out.shape[0], -1))\n",
    "        print(out.shape)\n",
    "        input()\n",
    "        return out, (hidden, cell)\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        hidden = torch.zeros(self.num_layers, batch_size, self.hidden_size).to(device)\n",
    "        cell = torch.zeros(self.num_layers, batch_size, self.hidden_size).to(device)\n",
    "        return hidden, cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a1c6983e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+=+++++++++\n",
      "TyHa q-hDcAH-VFzww;WWv-ecYK&&comhQhmtPf'KjNgvbQ\n",
      "ppSVv3IcxtRP,3?EaM\n",
      "ikr!gTutWENALsb,qpkPwI??UgZuQkQVv!d\n",
      "+++++++++++++++++\n",
      " 2.5038496398925782+=+++++++++\n",
      "Tyrert an! aibe ieg for wike fesw kas ursok tshitef had en auyvet tors, gory oud sorwe soe wof thisd I\n",
      "+++++++++++++++++\n",
      " 2.3083114624023438+=+++++++++\n",
      "Ty nathe gienc he she het,, heve houe leand, prefy beit and I and fow rorures shake the,\n",
      "Whe of fay.\n",
      "\n",
      "\n",
      "+++++++++++++++++\n",
      " 2.398551330566406+=+++++++++\n",
      "Ty, yow be the thim the theat hous bes, glings\n",
      "Gowe nou, I bay the me bete thers or, a mothere such on\n",
      "+++++++++++++++++\n",
      " 2.1592558288574217+=+++++++++\n",
      "Tyur hushom the then tham is in bancy the he elest ighonce:\n",
      "And if\n",
      "I hincetenss mer for its where, cre\n",
      "+++++++++++++++++\n",
      " 2.1172967529296876+=+++++++++\n",
      "Tyn henhey, what om witarond cay; diso tiis lons.\n",
      "\n",
      "Nard; waas the hath hath\n",
      "I fing newer.\n",
      "\n",
      "FUUES:\n",
      "Yew \n",
      "+++++++++++++++++\n",
      " 2.067519073486328+=+++++++++\n",
      "Ty brown harchsinn the plad\n",
      "and dblet.\n",
      "\n",
      "FLICER:\n",
      "A Rond gage brcevent the my on tree.\n",
      "\n",
      "CGord made he th\n",
      "+++++++++++++++++\n",
      " 1.7182891845703125+=+++++++++\n",
      "Tyes haten:\n",
      "The doy and breter.\n",
      "\n",
      "RICTORD OI\n",
      "ENIG:\n",
      "E litely and brat's by the coud, be't the reall the \n",
      "+++++++++++++++++\n",
      " 1.9591555786132813+=+++++++++\n",
      "Ty do thee be fill and whis I herulentrnys\n",
      "And you Mbaster,\n",
      "O arly\n",
      "The with the the ceentor:\n",
      "You untan\n",
      "+++++++++++++++++\n",
      " 1.8302748107910156+=+++++++++\n",
      "Ty brove aiakon eque to shall Note,\n",
      "And is bett lient so\n",
      "enole fell tonengle i propeace and bows a thi\n",
      "+++++++++++++++++\n",
      " 1.8356694030761718+=+++++++++\n",
      "Ty fold aft sarn than him fever I for bear with st twunth so port mer.\n",
      "\n",
      "PONE YARD:\n",
      "No the wely him tha\n",
      "+++++++++++++++++\n",
      " 2.0159985351562575+=+++++++++\n",
      "Tyselup aint\n",
      "Ik tling not shall the wactind ming the will the daod is souls, a wile.\n",
      "\n",
      "HUEEN IUS:\n",
      "O dum\n",
      "+++++++++++++++++\n",
      " 1.8926010131835938"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/pytorch/aten/src/ATen/native/cuda/Loss.cu:247: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [0,0,0] Assertion `t >= 0 && t < n_classes` failed.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "cuDNN error: CUDNN_STATUS_INTERNAL_ERROR",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_7017/88978820.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwindow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m             \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwindow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_7017/1018908618.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, X, hidden, cell)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgru\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    689\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_forward_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 691\u001b[0;31m             result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n\u001b[0m\u001b[1;32m    692\u001b[0m                               self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[1;32m    693\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: cuDNN error: CUDNN_STATUS_INTERNAL_ERROR"
     ]
    }
   ],
   "source": [
    "model = CharRNN(len(char2ids), 256, 2, len(char2ids)).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "check_every = 100\n",
    "\n",
    "def generate(model, init_str=\"Ty\", prediction_len=100, temperature=0.85):\n",
    "    hidden, cell = model.init_hidden(batch_size)\n",
    "    init_inp = torch.tensor([char2ids[char] for char in init_str]).long()\n",
    "    pred = init_str\n",
    "\n",
    "    for p in range(len(init_str) - 1):\n",
    "        _, hidden, cell = model(init_inp[p].view(1).to(device), hidden, cell)\n",
    "\n",
    "    last_char = init_inp[-1]\n",
    "\n",
    "    for p in range(prediction_len):\n",
    "        output, hidden, cell = model(last_char.view(1).to(device), hidden, cell)\n",
    "        output_distance = output.data.view(-1).div(temperature).exp()\n",
    "        top_char = torch.multinomial(output_distance, 1)[0]\n",
    "        predicted_char = idx2char[int(top_char) + 1]\n",
    "        pred += predicted_char\n",
    "        last_char = torch.tensor(char2ids[predicted_char])\n",
    "\n",
    "    return pred\n",
    "\n",
    "for epoch in range(10):\n",
    "    for j, (window, target) in enumerate(loader):\n",
    "        model.zero_grad()\n",
    "        hidden, cell = model.init_hidden(batch_size)\n",
    "        optimizer.zero_grad()\n",
    "        window = window.to(device)\n",
    "        target = target.to(device)\n",
    "        loss = 0\n",
    "        \n",
    "        for i in range(window.shape[1]): \n",
    "            out, hidden, cell = model(window[:,i], hidden, cell)  \n",
    "            loss += criterion(out, target[:,i])\n",
    "\n",
    "        if j%check_every == 0:\n",
    "            print('+=+++++++++')\n",
    "            print(generate(model))\n",
    "            print(\"+++++++++++++++++\")\n",
    "            \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print(f'\\r {loss.item() / window.shape[1]}', end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ccd47a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
