{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef24211a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tarfile\n",
    "\n",
    "file = tarfile.open('./jsb_chorales.tgz', 'r')\n",
    "file.extractall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e528afcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "DATASET_DIR = './jsb_chorales'\n",
    "\n",
    "class BachChorales(Dataset):\n",
    "    def __init__(self, path, window_size=32, transforms=None):\n",
    "        self.path = path\n",
    "        self.window_size = window_size\n",
    "        self.transforms = transforms\n",
    "        self.chorales = [pd.read_csv(os.path.join(path, p)) for p in os.listdir(os.path.join(path))]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.chorales)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        chorale = self.chorales[idx]\n",
    "        chorale = np.array(chorale)\n",
    "        chorale = chorale.reshape(-1,1)\n",
    "        chorale = chorale[:self.window_size*4+1] # Add one for target\n",
    "        chorale -= 36 # Subtract lowest node so all nodes are in range 0,46\n",
    "        chorale, target = chorale[:-1], chorale[-1]\n",
    "        sample = (chorale, target)\n",
    "        if self.transforms:\n",
    "            sample = self.transforms(sample)\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e12a85fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.transforms import Compose\n",
    "\n",
    "model = nn.Sequential(*[\n",
    "    nn.RNN(1,1,20,batch_first=True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e53446b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 128, 1]) torch.Size([32, 1])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 128, 1])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class ToTensor(object):\n",
    "    def __call__(self, sample):\n",
    "        chorale, target = sample\n",
    "        chorale = torch.tensor(chorale, dtype=torch.float)\n",
    "        target = torch.tensor(target, dtype=torch.float)\n",
    "        return (chorale, target)\n",
    "\n",
    "transforms = Compose([\n",
    "    ToTensor()\n",
    "])\n",
    "\n",
    "dataset = BachChorales(os.path.join(DATASET_DIR,'train'), transforms=transforms)\n",
    "loader = DataLoader(dataset, batch_size=32)\n",
    "chorales, targets = next(iter(loader))\n",
    "print(chorales.shape, targets.shape)\n",
    "out, hc = model(chorales)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ee806aca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1208.2098388671875\n",
      "1274.236083984375\n",
      "1236.970703125\n",
      "1238.7669677734375\n",
      "1276.3419189453125\n",
      "1245.673095703125\n",
      "1216.258544921875\n",
      "1271.2977294921875\n",
      "1196.7625732421875\n",
      "1262.7218017578125\n",
      "1225.8726806640625\n",
      "1227.8597412109375\n",
      "1265.5177001953125\n",
      "1235.133056640625\n",
      "1206.039306640625\n",
      "1260.99560546875\n",
      "1186.9840087890625\n",
      "1252.85400390625\n",
      "1216.3544921875\n",
      "1218.508056640625\n",
      "1256.249267578125\n",
      "1226.125732421875\n",
      "1197.326171875\n",
      "1252.227294921875\n",
      "1178.6734619140625\n",
      "1244.472900390625\n",
      "1208.2734375\n",
      "1210.56884765625\n",
      "1248.3807373046875\n",
      "1218.48095703125\n",
      "1189.9359130859375\n",
      "1244.7991943359375\n",
      "1171.6485595703125\n",
      "1237.4097900390625\n",
      "1201.4910888671875\n",
      "1203.9403076171875\n",
      "1241.8529052734375\n",
      "1212.187255859375\n",
      "1183.905517578125\n",
      "1238.797607421875\n",
      "1166.0355224609375\n",
      "1231.8323974609375\n",
      "1196.203857421875\n",
      "1198.8424072265625\n",
      "1236.90234375\n",
      "1207.4832763671875\n",
      "1179.4644775390625\n",
      "1234.442626953125\n",
      "1162.0230712890625\n",
      "1227.9036865234375\n",
      "1192.5335693359375\n",
      "1195.3529052734375\n",
      "1233.559814453125\n",
      "1204.348388671875\n",
      "1176.5419921875\n",
      "1231.6103515625\n",
      "1159.4425048828125\n",
      "1225.40283203125\n",
      "1190.218994140625\n",
      "1193.17138671875\n",
      "1231.486083984375\n",
      "1202.417236328125\n",
      "1174.752197265625\n",
      "1229.885009765625\n",
      "1157.8775634765625\n",
      "1223.8916015625\n",
      "1188.8243408203125\n",
      "1191.8594970703125\n",
      "1230.2412109375\n",
      "1201.2586669921875\n",
      "1173.6787109375\n",
      "1228.8494873046875\n",
      "1156.93701171875\n",
      "1222.981689453125\n",
      "1187.9827880859375\n",
      "1191.0657958984375\n",
      "1229.4853515625\n",
      "1200.552734375\n",
      "1173.0218505859375\n",
      "1228.213134765625\n",
      "1156.356201171875\n",
      "1222.4169921875\n",
      "1187.4580078125\n",
      "1190.5682373046875\n",
      "1229.008544921875\n",
      "1200.1044921875\n",
      "1172.6025390625\n",
      "1227.8043212890625\n",
      "1155.980712890625\n",
      "1222.0496826171875\n",
      "1187.114013671875\n",
      "1190.239990234375\n",
      "1228.6920166015625\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_9229/1668901928.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    305\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 307\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    155\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-2)\n",
    "\n",
    "for epoch in range(50):\n",
    "    for chorales, target in loader:\n",
    "        out, _ = model(chorales)\n",
    "        out = out[:,-1]\n",
    "        loss = criterion(out, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print(loss.item())\n",
    "        optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fca59aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
